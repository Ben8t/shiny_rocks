id: load_orders_snowflake
namespace: mds_shiny_rocks.product
description: |
  When data are generated upstream, this flow ingest the `orders` data into Google Cloud Storage and BigQuery.

labels:
  - key: tag
    value: load

inputs:
  - name: orders_data
    type: URI

  - name: order_date
    type: DATE

tasks:

  - id: create_table
    type: io.kestra.plugin.jdbc.snowflake.Query
    sql: |
      CREATE TABLE IF NOT EXISTS SHINY_ROCKS.PUBLIC.ORDERS (
        user_id STRING ,
        order_id STRING ,
        order_date STRING ,
        product_id INTEGER ,
        utm_source STRING
        );

  - id: extract_internal_stage
    type: io.kestra.plugin.jdbc.snowflake.Upload
    from: "{{ inputs.orders_data }}"
    fileName: orders.csv
    prefix: "{{ inputs.order_date }}"
    stageName: "@shiny_rocks.public.%orders"
    compress: true

  - id: load_table
    type: io.kestra.plugin.jdbc.snowflake.Query
    sql: |
      COPY INTO SHINY_ROCKS.PUBLIC.ORDERS
      FROM @shiny_rocks.public.%orders
      FILE_FORMAT = (type = csv field_optionally_enclosed_by='"' skip_header = 1)
      PATTERN = '.*orders.csv.gz';

triggers:

  - id: get_data
    type: io.kestra.core.models.triggers.types.Flow
    inputs:
      orders_data: "{{ outputs.file_outputs.uris['orders.csv'] }}"
      order_date: "{{ outputs.run_date.value }}"
    conditions:
      - type: io.kestra.core.models.conditions.types.ExecutionFlowCondition
        namespace: mds_shiny_rocks.product
        flowId: produce_data
      - type: io.kestra.core.models.conditions.types.ExecutionStatusCondition
        in:
          - SUCCESS

taskDefaults:
  - type: io.kestra.plugin.jdbc.snowflake.Query
    values:
      url: jdbc:snowflake://hzbjgxb-sn54742.snowflakecomputing.com?warehouse=COMPUTE_WH
      username: demo
      password: MDS2023_password

  - type: io.kestra.plugin.jdbc.snowflake.Upload
    values:
      url: jdbc:snowflake://hzbjgxb-sn54742.snowflakecomputing.com?warehouse=COMPUTE_WH
      username: demo
      password: MDS2023_password