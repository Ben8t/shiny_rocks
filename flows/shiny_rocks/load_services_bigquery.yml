id: load_services_bigquery
namespace: shiny_rocks.product
description: |
  When data are generated upstream, this flow ingest the `services` data into Google Cloud Storage and BigQuery.

labels:
  tag: load

inputs:
  - id: services_data
    type: URI

  - id: run_date
    type: DATE

tasks:

  - id: extract
    type: io.kestra.plugin.gcp.gcs.Upload
    serviceAccount: '{{ secret("GCP_CREDS") }}'
    from: "{{ inputs.services_data }}"
    to: gs://shiny_rocks_project/app_log/services/{{ inputs.run_date }}/services.csv

  - id: load
    type: io.kestra.plugin.gcp.bigquery.LoadFromGcs
    from: 
      - "{{ outputs.extract.uri }}"
    projectId: "kestra-sandbox"
    destinationTable: "shiny_rocks.services"
    serviceAccount: '{{ secret("GCP_CREDS") }}'
    format: CSV
    autodetect: true
    csvOptions:
      fieldDelimiter: ","
    timePartitioningField: "run_date"

triggers:

  - id: get_data
    type: io.kestra.plugin.core.trigger.Flow
    inputs:
      services_data: "{{ outputs.python.outputFiles['services.csv'] }}"
      run_date: "{{ outputs.run_date.value }}"
    conditions:
      - type: io.kestra.plugin.core.condition.ExecutionFlowCondition
        namespace: shiny_rocks.product
        flowId: produce_data
      - type: io.kestra.plugin.core.condition.ExecutionStatusCondition
        in:
          - SUCCESS